"""add_completion_boolean_fields

Revision ID: 7b088aebd544
Revises: 27f7d40373ea
Create Date: 2025-09-25 20:31:41.713268

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision = '7b088aebd544'
down_revision = '27f7d40373ea'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('langchain_pg_embedding')
    op.drop_table('langchain_pg_collection')
    
    # Add completion boolean fields to scenarios table (only if they don't exist)
    # Check if columns exist before adding them
    connection = op.get_bind()
    
    # Get existing columns
    result = connection.execute(sa.text("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name='scenarios' AND column_name IN ('name_completed', 'description_completed', 'personas_completed', 'scenes_completed', 'images_completed', 'learning_outcomes_completed', 'ai_enhancement_completed')
    """))
    existing_columns = [row[0] for row in result.fetchall()]
    
    # Add missing columns
    columns_to_add = [
        ('name_completed', sa.Column('name_completed', sa.Boolean(), nullable=True)),
        ('description_completed', sa.Column('description_completed', sa.Boolean(), nullable=True)),
        ('personas_completed', sa.Column('personas_completed', sa.Boolean(), nullable=True)),
        ('scenes_completed', sa.Column('scenes_completed', sa.Boolean(), nullable=True)),
        ('images_completed', sa.Column('images_completed', sa.Boolean(), nullable=True)),
        ('learning_outcomes_completed', sa.Column('learning_outcomes_completed', sa.Boolean(), nullable=True)),
        ('ai_enhancement_completed', sa.Column('ai_enhancement_completed', sa.Boolean(), nullable=True))
    ]
    
    for column_name, column_def in columns_to_add:
        if column_name not in existing_columns:
            op.add_column('scenarios', column_def)
    
    # Set default values for existing records
    op.execute("UPDATE scenarios SET name_completed = FALSE WHERE name_completed IS NULL")
    op.execute("UPDATE scenarios SET description_completed = FALSE WHERE description_completed IS NULL")
    op.execute("UPDATE scenarios SET personas_completed = FALSE WHERE personas_completed IS NULL")
    op.execute("UPDATE scenarios SET scenes_completed = FALSE WHERE scenes_completed IS NULL")
    op.execute("UPDATE scenarios SET images_completed = FALSE WHERE images_completed IS NULL")
    op.execute("UPDATE scenarios SET learning_outcomes_completed = FALSE WHERE learning_outcomes_completed IS NULL")
    op.execute("UPDATE scenarios SET ai_enhancement_completed = FALSE WHERE ai_enhancement_completed IS NULL")
    
    # Make columns NOT NULL with default FALSE
    op.alter_column('scenarios', 'name_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'description_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'personas_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'scenes_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'images_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'learning_outcomes_completed', nullable=False, server_default='false')
    op.alter_column('scenarios', 'ai_enhancement_completed', nullable=False, server_default='false')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Remove completion boolean fields from scenarios table
    op.drop_column('scenarios', 'ai_enhancement_completed')
    op.drop_column('scenarios', 'learning_outcomes_completed')
    op.drop_column('scenarios', 'images_completed')
    op.drop_column('scenarios', 'scenes_completed')
    op.drop_column('scenarios', 'personas_completed')
    op.drop_column('scenarios', 'description_completed')
    op.drop_column('scenarios', 'name_completed')
    
    op.create_table('langchain_pg_collection',
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('uuid', name='langchain_pg_collection_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_table('langchain_pg_embedding',
    sa.Column('collection_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('embedding', pgvector.sqlalchemy.Vector(), autoincrement=False, nullable=True),
    sa.Column('document', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('custom_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['collection_id'], ['langchain_pg_collection.uuid'], name=op.f('langchain_pg_embedding_collection_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('uuid', name=op.f('langchain_pg_embedding_pkey'))
    )
    # ### end Alembic commands ###
